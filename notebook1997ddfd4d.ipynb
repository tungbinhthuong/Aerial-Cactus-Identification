{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport zipfile\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        if filename.find('.zip')>-1:\n            zipfile.ZipFile(os.path.join(dirname, filename)).extractall('/kaggle/working/'+filename.replace('.zip',''))\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import Non-PyTorch Modules will be used in the lab\n\nimport time\nfrom imageio import imread\nfrom matplotlib.pyplot import imshow\nimport matplotlib.pylab as plt\nimport pandas as pd\nfrom PIL import Image, ImageDraw, ImageFont\nimport random\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import PyTorch Modules will be used in the lab\n\nimport torch \nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nfrom torchvision import transforms\nimport torch.nn as nn\ntorch.manual_seed(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keras Modules\n\nimport keras\nfrom keras.layers import Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import to_categorical\nfrom keras.layers.convolutional import Conv2D # to add convolutional layers\nfrom keras.layers.convolutional import MaxPooling2D # to add pooling layers\nfrom keras.layers import Flatten # to flatten data for fully connected layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !unzip '../input/aerial-cactus-identification/test.zip'\n# !unzip '../input/aerial-cactus-identification/test.zip'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"work_dir = '/kaggle/working'\ntrain_data_dir = '/kaggle/working/train/train'\ntest_data_dir = '/kaggle/working/test/test'\ntrain_csv = '/kaggle/input/aerial-cactus-identification/train.csv'\nsample_csv_path  = '/kaggle/input/aerial-cactus-identification/sample_submission.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset():\n    def __init__(self,data_dir,data_csv,transform=None):\n        self.csv=pd.read_csv(data_csv)\n        self.data_dir=data_dir\n        self.transform=transform\n        self.len=self.csv.shape[0]\n        \n    def __len__(self):\n        return self.len\n    \n    def __getitem__(self,idx):\n        img_name=self.data_dir+self.csv.iloc[idx,0]\n        image=Image.open(img_name)\n        y=self.csv.iloc[idx,1]\n        if self.transform:\n            image=self.transform(image)\n        return image,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_csv='../input/aerial-cactus-identification/train.csv'\ntrain = pd.read_csv(train_csv)\nsample = pd.read_csv(sample_csv_path)\nsample['has_cactus'] = sample['has_cactus'].astype(str)\ntrain['has_cactus'] = train['has_cactus'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = Dataset(train_data_dir,train_csv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(rescale = 1./255)\nbatch_size = 200","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = datagen.flow_from_dataframe(dataframe = train[:15001],\n                                            directory = train_data_dir,\n                                            x_col = 'id',\n                                            y_col = 'has_cactus',\n                                            class_mode = 'binary',\n                                            batch_size = batch_size,\n                                            target_size = (32,32))\n\nvalidation_generator = datagen.flow_from_dataframe(dataframe = train[15000:],\n                                                 directory = train_data_dir,\n                                                 x_col = 'id',\n                                                y_col = 'has_cactus',\n                                                 class_mode = 'binary',\n                                                 batch_size = 50,\n                                                target_size = (32,32))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(num_classes):\n    models = Sequential()\n    models.add(Conv2D(16, (3, 3), strides = (1, 1), activation = 'relu', input_shape = (32, 32, 3)))\n    models.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n    models.add(Conv2D(64, (3, 3), strides = (1, 1), activation = 'relu', input_shape = (32, 32, 3)))  \n    models.add(MaxPooling2D(pool_size = (2, 2), strides = (1, 1)))\n    models.add(Conv2D(128, (3, 3), strides = (1, 1), activation = 'relu', input_shape = (32, 32, 3)))  \n    models.add(MaxPooling2D(pool_size = (2, 2), strides = (1, 1)))\n    models.add(Conv2D(256, (3, 3), strides = (1, 1), activation = 'relu', input_shape = (32, 32, 3)))  \n    models.add(MaxPooling2D(pool_size = (2, 2), strides = (1, 1)))\n  \n    models.add(Flatten())\n    models.add(Dense(512, activation = 'relu'))\n    models.add(Dense(num_classes, activation = 'sigmoid'))\n    models.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    return models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callback = keras.callbacks.EarlyStopping(monitor = 'loss', \n                                        patience = 5, \n                                        restore_best_weights = True,\n                                        verbose = 2)\nmodel.fit_generator(generator = train_generator,\n                    epochs = 50, \n                    verbose = 2, \n                    validation_data = validation_generator,\n                   callbacks = [callback]\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_history = model.history.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_history['accuracy'])\nplt.show()\nplt.plot(train_history['val_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook\nimport tensorflow as tf\npreds = []\nfor fname in tqdm_notebook(sample['id']):\n    path = os.path.join(test_data_dir,fname)\n    \n    img_pil = Image.open(path)\n    image = np.array(img_pil)/255\n    pred = model.predict(image[tf.newaxis, ...])\n    preds.append(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample\npreds = np.array(preds).reshape(4000, -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['has_cactus'] = preds\nsubmission['has_cactus'] = submission['has_cactus'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('/kaggle/working/submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}